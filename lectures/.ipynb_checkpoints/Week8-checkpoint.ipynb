{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is the last week and our goal today is to use what we have learned so far to analyze new data: the tweets of the members of the House of Representatives. \n",
    "\n",
    "Remember that the Wikipedia network showed a nuanced and complex picture of the various kinds of connections between politicians that arise from the political system. And how our text-analysis also showed evidence of the many small cases and issues that fill the days of real-world American politicians.\n",
    "\n",
    "Well, as we all know *nuance is sometimes a little bit boring*, so today, we're going to a place without much nuance. **Twitter**. Twitter has become one of the main communication channels between politicians and the electorate, and we hope you'll find that the things that are going on on Twitter will fit your prejudices better ... it will have a lot less nuance. \n",
    "\n",
    "We will also learn about _sentiment analysis_, a topic which is pretty useless when it comes to Wikipedia (because all Wikipedia text is designed to be neutral), but which is highly useful to analyze Twitter data (and many other things).\n",
    "\n",
    "The overview for today is:\n",
    "\n",
    "* (Optional) Download the Twitter data.\n",
    "* Analyze and visualize the retweets network of the members of the House.\n",
    "* Learn about sentiment analysis.\n",
    "* Analyze the text of the tweets (using TF-IDF and sentiment analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - (Optional) Download the Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first exercise, we will use the Twitter API to download the 200 most recent tweets of the members of the House of Representatives. \n",
    "\n",
    "Twitter data could be useful for your future data projects, so we encourage you to go through this exercise. However, ***note that this exercise is optional,*** meaning it will not be included in your second assignment. \n",
    "\n",
    "* If you want to *skip the Twitter data download part*, jump to Part 1 of the exercises and use the data provided by us. You will find the Twitter handles of the members of the house [here](https://github.com/suneman/socialgraphs2018/blob/master/files/data_twitter/H115_tw.csv), and the 200 most recent tweets for each member [here](https://github.com/suneman/socialgraphs2018/tree/master/files/data_twitter/tweets.zip). Each file is named as the Twitter handle of a member, and each line of a file contains a tweet (from the most recent to the oldest). By _handle_ we mean a user's id on Twitter.\n",
    "\n",
    "If, instead, you want to learn how to download Twitter data, follow the steps below for success.\n",
    "\n",
    "_Exercise_ 1: Download Twitter Data.\n",
    "> To get access to the Twitter API, you will need to create an app. You can follow these steps:\n",
    ">\n",
    "> * Create a Twitter account (you can use your one if you already have one).\n",
    "> * Apply for a Twitter developer account [here](https://developer.twitter.com/en/apply-for-access.html)\n",
    "> * Create an app that interacts with the Twitter API. Go to https://developer.twitter.com/en/apps and click _\"Create an app\"_.\n",
    "> * Fill out the form, agree to the terms, and click _“Create”_. **Note: you can use the link to your Twitter page as \"_Website URL_\" (e.g. ht<span>tps://</span>twitter.com/my_twitter_handle)**.\n",
    "> * In the next page, click on _Keys and Access Tokens_ tab, and copy your _API key_ and _API secret_. Scroll down and click _Create my access token_, and copy your _Access token_ and _Access token secret_.\n",
    "\n",
    "> We are almost set to use the Twitter API! We will use a Python library called [python-twitter](https://github.com/bear/python-twitter) to connect to Twitter API and download data. There are [many other libraries](https://developer.twitter.com/en/docs/developer-utilities/twitter-libraries.html) that let you use Twitter API. We chose python-twitter because it is simple to use (and it fully supports the Twitter API).\n",
    "> * Install python-twitter using one of the following: \n",
    ">    * `conda install -c jacksongs python-twitter` \n",
    ">    * `pip install python-twitter`\n",
    "> * Check out python-twitter [documentation](https://python-twitter.readthedocs.io/en/latest/getting_started.html) and [examples](https://github.com/bear/python-twitter/tree/master/examples) to get started with the API. Use the API keys and tokens for the app you created above to create an instance of the [`twitter.Api`](https://python-twitter.readthedocs.io/en/latest/twitter.html#twitter.api.Api) class.\n",
    "> * Download the twitter handles of the members of the list [_u-s-representatives_](https://twitter.com/cspan/lists/u-s-representatives/members?lang=en). This list contains the handles of the current members of the house of representatives. _Hint:_ Use the method [`twitter.api.Api.GetListMembers`](https://python-twitter.readthedocs.io/en/latest/twitter.html?highlight=getlistmembers#twitter.api.Api.GetListMembers). \n",
    "> *  Retrieve the  _name_ associated to each Twitter handle (the one displayed in a user's Twitter page under the profile picture in bold). _Hint:_ Use the method [`twitter.api.Api.UsersLookup`](https://python-twitter.readthedocs.io/en/latest/twitter.html?highlight=getlistmembers#twitter.api.Api.UsersLookup).\n",
    "> * Tricky bit! Find the party associated to each Twitter handle using the [list of the house of representatives members on Wikipedia](https://github.com/suneman/socialgraphs2018/blob/master/files/data_US_congress/H115.csv). What you need to do is to match  _names_ with the Wikipedia page names. Be creative to find a solution! _Note:_ Some members don't have a Twitter account, but others have two. In the latter case, prefer the account that is related to the house of representatives (e.g. prefer https://twitter.com/RepRoKhanna over https://twitter.com/rokhanna). Create a `pandas.Dataframe` with twitter handles and corresponding parties and save it.\n",
    "> * Download the 200 most recent Tweets for each member of the house. Save the tweets of each member in a different file. _Hint:_ Use the method [`twitter.api.Api.GetUserTimeline`](https://python-twitter.readthedocs.io/en/latest/twitter.html?highlight=getlistmembers#twitter.api.Api.GetUserTimeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - The network of retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retweets are re-posting of tweets that were often originated by another user. Often, they indicate trust in the message included in the original tweet and in the original author, and agreement with the message contents ([as found also by scientific studies](http://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/download/10555/10467)). This suggests that, by looking at how representatives retweet each other, we can understand something about the relations between them.\n",
    "\n",
    "_Exercise_ 2: Build the network of retweets.\n",
    "We will now build a network that has as nodes the Twitter handles of the members of the house, and direct edges between nodes A and B if A has retweeted content posted by B. We will build a weighted network, where the weight of an edge is equal to the number of retweets. You can build the network following the steps below (and you should  be able to reuse many of the functions you wrote in previous weeks):\n",
    "\n",
    "> * Consider the 200 most recent tweets written by each member of the house (click \"Download\" to get the zip file [here](https://github.com/suneman/socialgraphs2018/tree/master/files/data_twitter/tweets.zip), or use the ones you produced in Part 1). For each file, use a regular expression to find retweets and to extract the Twitter handle of the user whose content was retweeted. All retweets begin with \"_RT @originalAuthor:_\", where \"_originalAuthor_\" is the handle of the user whose content was retweeted (and the part of the text you want to extract).\n",
    "> * For each retweet, check if the handle retweeted is the one of a member of the house. If yes, keep it. If no, discard it.\n",
    "> * Use a NetworkX [`DiGraph`](https://networkx.github.io/documentation/development/reference/classes.digraph.html) to store the network. Use weighted edges to account for multiple retweets. Store also the party of each member as a node attribute (use the data in [this file](https://github.com/suneman/socialgraphs2018/blob/master/files/data_twitter/H115_tw.csv), or the data you downloaded in Part 1). Remove self-loops (edges that connect a node with itself).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _Exercise_ 3: Visualize the network of retweets and investigate differences between the parties.\n",
    "> * Visualize the network using the [Networkx draw function](https://networkx.github.io/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw.html#networkx.drawing.nx_pylab.draw), and nodes coordinates from the force atlas algorithm (see Week 5, Exercise 2). _Hint: use the undirected version of the graph to find the nodes positions for better results, but stick to the directed version for all measurements._ Plot nodes in colors according to their party (e.g. 'red' for republicans and 'blue' for democrats) and set the nodes' size proportional to their total degree. \n",
    ">   * Compare the network of Retweets with the network of Wikipedia pages (Week 5, exercise 2). Do you observe any difference? How do you explain them?\n",
    "> * Now set the nodes' size proportional to their betweenness centrality. What do you observe?\n",
    "> * Repeat the point above using eigenvector centrality instead. Is there any difference? Can you explain why?\n",
    "> * Who are the three nodes with highest degree within each party? And eigenvector centrality? And betweenness centrality?\n",
    "> * Plot on the same figure the distribution of outgoing strength for the republican and democratic nodes (e.g. the sum of the weight on outgoing links). Which party is more active in retweeting other members of the house?\n",
    "> * Find the 3 members of the republican party that have retweet more often tweets from democratic members. Repeat the measure for the democratic members. Can you explain your results by looking at the Wikipedia pages of these members of the house?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _Exercise_ 4: Community detection.\n",
    "> * Use [the Python Louvain-algorithm implementation](http://perso.crans.org/aynaud/communities/) to find communities in the full house of representatives network. Report the value of modularity found by the algorithm. Is it higher or lower than what you found for the Wikipedia network? Comment on your result.\n",
    "    >   * \\[**Note**: This implementation is now available as Anaconda package. Install with `conda` as explained [here](https://anaconda.org/auto/python-louvain)\\]. \n",
    "    >   * You can also try the *Infomap* algorithm instead if you're curious. Go to [this page]. (http://www.mapequation.org/code.html) and search for 'python'. It's harder to install, but a better community detection algorithm.\n",
    "> * Visualize the network, using the Force Atlas algorithm (see Lecture 5, exercise 2). This time assign each node a different color based on their _community_. Describe the structure you observe.\n",
    "> * Compare the communities found by your algorithm with the parties by creating a matrix $\\mathbf{D}$ with dimension $(B \\times C$, where $B$ is the number of parties and $C$ is the number of communities. We set entry $D(i,j)$ to be the number of nodes that party $i$ has in common with community $j$. The matrix $\\mathbf{D}$ is what we call a [**confusion matrix**](https://en.wikipedia.org/wiki/Confusion_matrix). \n",
    "> * [Plot the confusion matrix](https://scipython.com/book/chapter-7-matplotlib/examples/visualizing-a-matrix-with-imshow/) and explain how well the communities you've detected correspond to the parties. Consider the following questions\n",
    ">   * Are there any republicans grouped with democrats (and vice versa)?\n",
    ">   * Does the community detection algorithm sub-divide the parties? Do you know anything about American politics that could explain such sub-divisions? Answer in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - What do republican and democratic members tweet about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now put to use all we have learned on language processing to find out the content of the tweets of democratic and republican members. \n",
    "\n",
    "_Exercise_ 5: TF-IDF of the republican and democratic tweets.\n",
    "> We will create two documents, one containing the words extracted from tweets of republican members, and the other for Democratic members. We will then use TF-IDF to compare the content of these two documents and create a word-cloud. The procedure you should use is exactly the same you used in exercise 2 of week 7. The main steps are summarized below: \n",
    "> * Create two large documents, one for the democratic and one for the republican party. Tokenize the pages, and combine the tokens into one long list including all the pages of the members of the same party. \n",
    ">   * Exclude all twitter handles.\n",
    ">   * Exclude punctuation.\n",
    ">   * Exclude stop words (if you don't know what stop words are, go back and read NLPP1e again).\n",
    ">   * Exclude numbers (since they're difficult to interpret in the word cloud).\n",
    ">   * Set everything to lower case.\n",
    ">   * Compute the TF-IDF for each document.\n",
    "> * Now, create word-cloud for each party. Are these topics less \"boring\" than the wikipedia topics? Why?  Comment on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is another highly useful technique which we'll use to make sense of the Twitter data. Experience shows that it might well be very useful when you get to the project stage of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **Video Lecture**: Uncle Sune talks about sentiment and his own youthful adventures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://www.youtube.com/embed/JuYcaYYlfrI\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x10e244b90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo(\"JuYcaYYlfrI\",width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reading: [Temporal Patterns of Happiness and Information in a Global Social Network: Hedonometrics and Twitter](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0026752) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Exercise_ 6: Sentiment over the Twitter data.\n",
    "> \n",
    "> * Download the LabMT wordlist. It's available as supplementary material from [Temporal Patterns of Happiness and Information in a Global Social Network: Hedonometrics and Twitter](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0026752) (Data Set S1). Describe briefly how the list was generated.\n",
    "> * Based on the LabMT word list, write a function that calculates sentiment given a list of tokens (the tokens should be lower case, etc).\n",
    "> * Create two lists: one including the tokenized tweets written by democratic members, and the other including the tokenized tweets written by republican members. Calculate the sentiment of each tweet and plot the distribution of tweet sentiment for each of the two lists. Are there significant differences between the two? Which party post more positive tweets?\n",
    "> * Compute the average _m_ and standard deviation $\\sigma$  of the tweets sentiment (considering tweets by both republican and democrats). \n",
    "> * Now consider only tweets with sentiment lower than m-2$\\sigma$. We will refer to them as _negative_ tweets.  Build a list containing the _negative_ tweets written by democrats, and one for republicans. Compute the TF-IDF for these two lists (use the same pre-processing steps in Exercise 5). Create a word-cloud for each of them. Are there differences between the positive contents posted by republicans and democrats?\n",
    "> * Repeat the point above, but considering _positive_ tweets instead (e.g. with sentiment larger than m+2$\\sigma$). Comment on your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
